{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este é um roteiro elementar de um pipeline ETL utilizando python. Foi desenvolvido para fins didáticos, com o propósito de demostrar o processo básico de análise de dados, nas suas três grandes etapas."
      ],
      "metadata": {
        "id": "ESWv1LEY2s0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando o ambiente\n",
        "Faremos alguns imports, que serão utilizados no processo."
      ],
      "metadata": {
        "id": "yQPgN7gr2SdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "WQ-27CP60TjT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRACT\n",
        "A primeira parte é a extração.\n",
        "\n",
        "\n",
        "Vamos executar o código abaixo.\n",
        "\n",
        "\n",
        "A primeira linha define a variável 'url' com a URL do site que queremos analisar. No caso, está sendo usado o site do UOL.\n",
        "\n",
        "\n",
        "Na segunda linha, estamos usando a biblioteca requests para fazer uma requisição HTTP GET à URL especificada. Isso recupera o conteúdo da página web.\n",
        "\n",
        "\n",
        "Terceira linha de código: Usando a biblioteca BeautifulSoup, estamos criando um objeto soup a partir do conteúdo da resposta da requisição. O objeto soup é uma representação hierárquica do HTML da página e facilita a navegação e análise dos elementos.\n",
        "\n",
        "\n",
        "Por fim, estamos buscando todos os elementos 'article' que possuem a classe CSS 'headlineMain' na página HTML representada pelo objeto soup. Estamos usando uma list comprehension para iterar sobre esses elementos encontrados e extrair o texto contido dentro deles usando item.text. Isso cria uma lista chamada data_list que contém os textos das manchetes principais do site UOL."
      ],
      "metadata": {
        "id": "sN9MEH_V2iGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.uol.com.br/'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "data_list = [item.text for item in soup.find_all('article', class_='headlineMain')]"
      ],
      "metadata": {
        "id": "GHDan4vo2MHO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A segunda parte é a transformação.\n",
        "\n",
        "Nesta linha de código, estamos usando a biblioteca pandas para criar um DataFrame a partir da lista data_list. Vamos por partes:\n",
        "\n",
        "1. A função pd.DataFrame() cria um DataFrame, que é uma estrutura de dados tabular semelhante a uma planilha ou tabela de banco de dados, a partir dos dados fornecidos.\n",
        "\n",
        "2. 'data_list': O primeiro argumento passado para a função pd.DataFrame() é a lista data_list que contém os textos das manchetes, extraídos na etapa anterior.\n",
        "\n",
        "3. 'columns=['dados']': O argumento columns é usado para especificar os nomes das colunas do DataFrame. No caso, estamos definindo o nome da coluna como 'dados'."
      ],
      "metadata": {
        "id": "--PPO_1z494X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.DataFrame(data_list, columns=['dados'])"
      ],
      "metadata": {
        "id": "lbWpKIYd2NmH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A terceira e última etapa é o carregamento.\n",
        "\n",
        "\n",
        "A linha de código abaixo exporta os dados contidos no DataFrame 'data_df' para um arquivo CSV chamado 'manchetes.csv', omitindo a inclusão da coluna de índices. Isso é útil para salvar os dados de suas manchetes ou de qualquer outro conjunto de dados em um formato que possa ser facilmente compartilhado, analisado ou importado em outras ferramentas ou plataformas.\n",
        "\n",
        "\n",
        "Aqui estamos tão somente exportando os dados extraídos para um arquivo no formato CSV, mas as possibilidades são imensas."
      ],
      "metadata": {
        "id": "b1F29-jz6kcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.to_csv('manchetes.csv', index=False)"
      ],
      "metadata": {
        "id": "AiG1ps3a2Psj"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}